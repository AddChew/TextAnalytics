{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBhOdd_ARk1d"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import ElectraTokenizerFast, ElectraForSequenceClassification, get_linear_schedule_with_warmup, AdamW, pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcFtQaaEUTz6"
   },
   "outputs": [],
   "source": [
    "def preprocessText(features, tokenizer, train=True, max_length=64, batchsize=8):\n",
    "\n",
    "  input_word_ids, input_type_ids, input_mask = tokenizer.batch_encode_plus(\n",
    "      features.Comments.tolist(),\n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True,\n",
    "      return_tensors='pt'\n",
    "  ).values()\n",
    "\n",
    "  labels = torch.from_numpy(features.Sentiment.values)\n",
    "  dataset = TensorDataset(input_word_ids, input_mask, labels)\n",
    "  dataloader = DataLoader(dataset, shuffle=train, batch_size=batchsize)\n",
    "\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhIabBmOWt1c"
   },
   "outputs": [],
   "source": [
    "def training(model, train_dataloader, train_size, optimizer, scheduler):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  epoch_loss = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for input_words, attention_masks, labels in train_dataloader:\n",
    "    input_words, attention_masks, labels = input_words.cuda(), attention_masks.cuda(), labels.cuda()\n",
    "    \n",
    "    outputs = model(input_words, attention_mask=attention_masks, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "    num_correct += torch.sum(preds==labels)\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "  avg_batch_loss = epoch_loss / len(train_dataloader)\n",
    "  acc = num_correct / train_size\n",
    "  print('Training Loss: {:.6f}, \\t Training Accuracy: {:.4f}'.format(avg_batch_loss, acc))\n",
    "\n",
    "  return avg_batch_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIgLc0tWZwzR"
   },
   "outputs": [],
   "source": [
    "def validating(model, val_dataloader, val_size):\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  epoch_loss = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for input_words, attention_masks, labels in val_dataloader:\n",
    "      input_words, attention_masks, labels = input_words.cuda(), attention_masks.cuda(), labels.cuda()\n",
    "      \n",
    "      outputs = model(input_words, attention_mask=attention_masks, labels=labels)\n",
    "      loss = outputs.loss\n",
    "      preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "      num_correct += torch.sum(preds==labels)\n",
    "      epoch_loss += loss.item()\n",
    "  \n",
    "  avg_batch_loss = epoch_loss / len(val_dataloader)\n",
    "  acc = num_correct / val_size\n",
    "  print('Validation Loss: {:.6f}, \\t Validation Accuracy: {:.4f}'.format(avg_batch_loss, acc))\n",
    "  print('-----------------------------------------------------------------------------------------------------------')\n",
    "  \n",
    "  return avg_batch_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKtn9v7-Zxc1"
   },
   "outputs": [],
   "source": [
    "def testing(modelpath, tokenizerpath, test, label2id, max_length, batchsize, savepath='./Electra/results.csv'):\n",
    "\n",
    "  test_size = len(test) \n",
    "  tokenizer = ElectraTokenizerFast.from_pretrained(tokenizerpath)\n",
    "  test_dataloader = preprocessText(test, tokenizer, train=False, max_length=max_length, batchsize=batchsize)\n",
    "  \n",
    "  model = AutoModelForSequenceClassification.from_pretrained(modelpath).cuda()\n",
    "  model.eval()\n",
    "\n",
    "  num_correct = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for input_words, attention_masks, labels in test_dataloader:\n",
    "      input_words, attention_masks, labels = input_words.cuda(), attention_masks.cuda(), labels.cuda()\n",
    "      \n",
    "      outputs = model(input_words, attention_mask=attention_masks, labels=labels)\n",
    "      probs, preds = torch.max(F.softmax(outputs.logits, dim=1), dim=1)\n",
    "      num_correct += torch.sum(preds == labels)\n",
    "\n",
    "      try:\n",
    "        all_preds = np.append(all_preds, preds.detach().cpu().numpy())\n",
    "      except:\n",
    "        all_preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      try:\n",
    "        all_labels = np.append(all_labels, labels.detach().cpu().numpy())\n",
    "      except:\n",
    "        all_labels = labels.detach().cpu().numpy()\n",
    "\n",
    "      try:\n",
    "        all_probs = np.append(all_probs, probs.detach().cpu().numpy())\n",
    "      except:\n",
    "        all_probs = probs.detach().cpu().numpy()\n",
    "\n",
    "  # Compute the accuracy\n",
    "  acc = num_correct / test_size\n",
    "\n",
    "  # Print out model performance\n",
    "  print('-----------------------------------------------------------------------------------------------------------')\n",
    "  print('Test Accuracy: {:.4f}'.format(acc))\n",
    "  print('-----------------------------------------------------------------------------------------------------------')\n",
    "  print(classification_report(all_labels, all_preds, target_names=['Positive', 'Neutral', 'Negative']))\n",
    "  print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "  # Append results to dataframe\n",
    "  id2label={v:k for k,v in label2id.items()}\n",
    "  results = test.copy()\n",
    "  results.Sentiment = results.Sentiment.apply(lambda x: id2label[x])\n",
    "  results['Prediction'] = np.array([id2label[x] for x in all_preds])\n",
    "  results['Confidence'] = all_probs\n",
    "\n",
    "  # Save results to a csv file\n",
    "  results.to_csv(savepath, index=False)\n",
    "\n",
    "  print('Model predictions have been saved successfully to {}!'.format(savepath))\n",
    "  print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24Cb3dPNZxhp"
   },
   "outputs": [],
   "source": [
    "def main(num_epochs, lr, train, val, test, modelpath, tokenizerpath, resultspath, max_length=64, batchsize=8):\n",
    "\n",
    "  electra_tokenizer = ElectraTokenizerFast.from_pretrained('google/electra-small-discriminator')\n",
    "\n",
    "  train_dataloader = preprocessText(train, electra_tokenizer, train=True, max_length=max_length, batchsize=batchsize)\n",
    "  val_dataloader = preprocessText(val, electra_tokenizer, train=False, max_length=max_length, batchsize=batchsize)\n",
    "\n",
    "  train_size = len(train)\n",
    "  val_size = len(val)\n",
    "\n",
    "  label2id = {'Positive': 0,\n",
    "              'Neutral': 1,\n",
    "              'Negative': 2}\n",
    "\n",
    "  model = ElectraForSequenceClassification.from_pretrained(\n",
    "      'google/electra-small-discriminator', \n",
    "      num_labels=3, \n",
    "      id2label={v:k for k,v in label2id.items()},\n",
    "      label2id=label2id,\n",
    "      max_length=64,\n",
    "      ).cuda()\n",
    "\n",
    "  num_train_steps = len(train_dataloader) * num_epochs\n",
    "  num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "  ]\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\n",
    "\n",
    "  best_epoch = 0\n",
    "  best_val_loss = float('inf')\n",
    "  best_val_acc = 0\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "\n",
    "    train_loss, train_acc = training(model, train_dataloader, train_size, optimizer, scheduler)\n",
    "    val_loss, val_acc = validating(model, val_dataloader, val_size)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "      best_epoch = epoch\n",
    "      best_val_loss = val_loss\n",
    "      best_val_acc = val_acc\n",
    "      model.save_pretrained(modelpath)\n",
    "\n",
    "  electra_tokenizer.save_pretrained(tokenizerpath)\n",
    "  print('Best Epoch {} \\t Validation Loss: {:.6f}, \\t Validation Accuracy: {:.4f}'.format(best_epoch, best_val_loss, best_val_acc))\n",
    "\n",
    "  testing(modelpath, tokenizerpath, test, label2id, max_length, batchsize, savepath=resultspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XH5EHiBI0wR"
   },
   "outputs": [],
   "source": [
    "def modelPipeline(modelpath, tokenizerpath, return_all_scores=True):\n",
    "  tokenizer = ElectraTokenizerFast.from_pretrained(tokenizerpath)\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(modelpath)\n",
    "  return pipeline(task='sentiment-analysis', model=model, tokenizer=tokenizer, device=0, return_all_scores=return_all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-dx8-WvR5yo"
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train = pd.read_csv('survey_2018_2019.csv', encoding='ISO-8859-1')\n",
    "train.Comments = train.Comments.str.replace(r'\\n', '')\n",
    "train.Comments = train.Comments.str.replace(r'\\r', '')\n",
    "\n",
    "# Validation and test dataset\n",
    "val = pd.read_csv('survey_2020_Jan.csv').append(pd.read_csv('survey_2020_Aug.csv'))\n",
    "val.Comments = val.Comments.str.replace(r'\\n', '')\n",
    "val.Comments = val.Comments.str.replace(r'\\r', '')\n",
    "\n",
    "# Perform validation test split\n",
    "val, test = train_test_split(val, test_size=0.5, random_state=20210501, stratify=val.Sentiment)\n",
    "\n",
    "# Convert labels to integers\n",
    "mapping = {'Positive': 0,\n",
    "           'Neutral': 1,\n",
    "           'Negative': 2}\n",
    "\n",
    "train.Sentiment = train.Sentiment.apply(lambda x: mapping[x])\n",
    "val.Sentiment = val.Sentiment.apply(lambda x: mapping[x])\n",
    "test.Sentiment = test.Sentiment.apply(lambda x: mapping[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0W-jxUDTCGn",
    "outputId": "d6f32707-5825-4f03-82e8-960ef8385d8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training Loss: 0.913478, \t Training Accuracy: 0.5773\n",
      "Validation Loss: 0.630132, \t Validation Accuracy: 0.7421\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Epoch 1\n",
      "Training Loss: 0.576044, \t Training Accuracy: 0.7818\n",
      "Validation Loss: 0.589571, \t Validation Accuracy: 0.7639\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Epoch 2\n",
      "Training Loss: 0.425640, \t Training Accuracy: 0.8459\n",
      "Validation Loss: 0.527594, \t Validation Accuracy: 0.7916\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Epoch 3\n",
      "Training Loss: 0.342950, \t Training Accuracy: 0.8834\n",
      "Validation Loss: 0.531823, \t Validation Accuracy: 0.7916\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Epoch 4\n",
      "Training Loss: 0.303958, \t Training Accuracy: 0.8940\n",
      "Validation Loss: 0.543473, \t Validation Accuracy: 0.7988\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Best Epoch 4 \t Validation Loss: 0.543473, \t Validation Accuracy: 0.7988\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Test Accuracy: 0.7850\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.80      0.71      0.75       289\n",
      "     Neutral       0.54      0.58      0.56       323\n",
      "    Negative       0.87      0.88      0.88       904\n",
      "\n",
      "    accuracy                           0.78      1516\n",
      "   macro avg       0.74      0.72      0.73      1516\n",
      "weighted avg       0.79      0.78      0.79      1516\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "Model predictions have been saved successfully to Electra/results.csv!\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters here\n",
    "num_epochs = 5\n",
    "lr = 2e-5\n",
    "modelpath = 'Electra/model'\n",
    "tokenizerpath = 'Electra/tokenizer'\n",
    "resultspath = 'Electra/results.csv'\n",
    "\n",
    "# Commence training\n",
    "main(num_epochs, lr, train, val, test, modelpath, tokenizerpath, resultspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gnUNUR-KTUq",
    "outputId": "0df11357-dce3-4aa9-cf21-0b9061b359b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'Positive', 'score': 0.005596943665295839},\n",
       "  {'label': 'Neutral', 'score': 0.050930269062519073},\n",
       "  {'label': 'Negative', 'score': 0.9434728026390076}]]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "classifier = modelPipeline(modelpath, tokenizerpath, return_all_scores=True)\n",
    "classifier(\"senior officer did a good job by ensure officer well being, but working in woodland checkpoint is tiring, and we tend to get sick easily. that's one of issue we couldn't control for the health. its not easy working on shift to maintain yourself to stay heathy and fit.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Electra-Small-PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
